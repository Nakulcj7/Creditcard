{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nakulcj7/Creditcard/blob/main/Credit_card_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Credit  Card Default Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The aim of a credit card default prediction project is to develop a machine learning model that can accurately predict which credit card users are likely to default on their payments in the future. The model should use historical data of credit card users such as their payment history, credit limit, age, education, and other demographic information to identify patterns and trends that can help predict default behavior. The project focuses on utilizing historical data of Customer's default payment in Taiwan.\n",
        "\n",
        "\n",
        "*   There were 30000 records and 25 attributes in the dataset.\n",
        "\n",
        "*   I started by importing the dataset, and necessary libraries and conducted exploratory data analysis (EDA) to get a clear insight into each feature by separating the dataset into numeric and categoric features. I did Univariate, Bivariate, and even multivariate analyses.\n",
        "\n",
        "*   After that, the outliers and null values were checked from the raw data. Data were transformed to ensure that it was compatible with machine learning models.\n",
        "*   In feature engineering we transformed raw data into a more useful and informative form, by encoding, feature manipulation, and feature selection. We handled target class imbalance using SMOTE.\n",
        "\n",
        "\n",
        "*   Then finally cleaned and scaled data was sent to various models, the metrics were made to evaluate the model, and we tuned the hyperparameters to make sure the right parameters were being passed to the model. To select the final model based on requirements, we checked model_result.\n",
        "\n",
        "\n",
        "*   When developing a machine learning model, it is generally recommended to track multiple metrics because each one highlights distinct aspects of model performance. We are, however, focusing more on the Recall score and F1 score because we are dealing with credit card data and our data is unbalanced.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite high returns, credit cards carry significant risks. The ever-expanding number of credit cards has achieved an expansion in how much credit card defaults and the subsequent enormous measure of bills and repayment data information have likewise carried specific hardships to the risk controllers. As a result, one of the primary concerns of banks is how to use the data generated by users and extract useful information to control risks, reduce the default rate, and control the growth of non-performing assets.\n",
        "\n",
        "A credit card issuer based in Taiwan wants to learn more about how likely its customers are to default on their payments and the main factors that influence this probability. The issuer's decisions regarding who to issue a credit card to and what credit limit to offer would be informed by this information. The issuer's future strategy, including plans to offer targeted credit products to their customers, would be informed by a better understanding of their current and potential customers as a result of this.\n",
        "# Objective\n",
        "\n",
        "*   \n",
        "\n",
        "    To determine the main factors that influence the likelihood of defaulting on a credit card.\n",
        "*   To determine the likelihood that Bank customers will default on their credit card payments.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# libraries that are used for analysis and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# libraries to do statistical analysis\n",
        "import math\n",
        "from scipy.stats import *\n",
        "\n",
        "# libraries used to pre-process\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# libraries used to implement models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "# libraries to evaluate performance\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import auc, accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "from sklearn.metrics import precision_score, f1_score, recall_score\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# library of warnings would assist in ignoring warnings issued\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# to set max column display\n",
        "pd.pandas.set_option('display.max_columns',None)"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Dataset\n",
        "clients_df = pd.read_csv('/content/drive/MyDrive/Almabetter/Creditcarddataset.csv', encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "Xx-_r4LcEHgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "# Viewing the top 5 rows to take a glimpse of the data\n",
        "clients_df.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "clients_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'number of rows : {clients_df.shape[0]}  \\nnumber of columns : {clients_df.shape[1]}')"
      ],
      "metadata": {
        "id": "8Uo9PFPHKEAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "clients_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "value=len(clients_df[clients_df.duplicated()])\n",
        "print(\"The number of duplicate values in the data set is = \",value)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that there is no duplicate values in the dataset."
      ],
      "metadata": {
        "id": "xpu-nh4FKmfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(clients_df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import missingno as msno\n",
        "msno.bar(clients_df, color='red',sort='ascending', figsize=(7,3), fontsize=12)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This confirms that there is zero null values in the dataset."
      ],
      "metadata": {
        "id": "KJxEuHGgLTvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "There are 30000 rows and 25 columns in the dataset. The dataset does not contain any duplicate or missing values.\n",
        "\n",
        "The given dataset is from the banking industry. Our task is to examine customer credit default and its causes.The proactive identification of customers most likely to default on loan payments is the first step in predicting customer loan default. This is typically done by dynamically analyzing pertinent customer data and actions.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "clients_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "clients_df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains data from credit card indistry in Taiwan and has collected\n",
        "the usage, historical payments and default status of the customers.\n",
        "# Attribute Information:\n",
        "\n",
        "*   ID : ID of each client\n",
        "\n",
        "*   LIMIT_BAL : Amount of given credit in NT dollars\n",
        "\n",
        "*   SEX : Gender (1=male, 2=female)\n",
        "\n",
        "*   EDUCATION : (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
        "\n",
        "*   MARRIAGE : Marital status (1=married, 2=single, 3=others)\n",
        "\n",
        "*   AGE : Age in years\n",
        "\n",
        "\n",
        "*   \n",
        "PAY_0 : Repayment status in September, 2005 (-2=no consumption, -1=pay duly, 0=the use of revolving credit, 1=payment delay for one month, 2=payment delay for two months, … 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
        "\n",
        "\n",
        "*   PAY_2 : Repayment status in August, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "*   PAY_3 : Repayment status in July, 2005 (scale same as above)\n",
        "\n",
        "*   PAY_4 : Repayment status in June, 2005 (scale same as above)\n",
        "\n",
        "*   PAY_5 : Repayment status in May, 2005 (scale same as above)\n",
        "\n",
        "*   PAY_6 : Repayment status in April, 2005 (scale same as above)\n",
        "\n",
        "*   BILL_AMT1 : Amount of bill statement in September, 2005 (NT dollar)\n",
        "*   BILL_AMT2 : Amount of bill statement in August, 2005 (NT dollar)\n",
        "\n",
        "*   BILL_AMT3 : Amount of bill statement in July, 2005 (NT dollar)\n",
        "*   BILL_AMT4 : Amount of bill statement in June, 2005 (NT dollar)\n",
        "\n",
        "*   BILL_AMT5 : Amount of bill statement in May, 2005 (NT dollar)\n",
        "\n",
        "*   BILL_AMT6 : Amount of bill statement in April, 2005 (NT dollar)\n",
        "*   PAY_AMT1 : Amount of previous payment in September, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   PAY_AMT2 : Amount of previous payment in August, 2005 (NT dollar)\n",
        "\n",
        "*   PAY_AMT3 : Amount of previous payment in July, 2005 (NT dollar)\n",
        "*   PAY_AMT4 : Amount of previous payment in June, 2005 (NT dollar)\n",
        "\n",
        "*   PAY_AMT5 : Amount of previous payment in May, 2005 (NT dollar)\n",
        "\n",
        "*   PAY_AMT6 : Amount of previous payment in April, 2005 (NT dollar)\n",
        "*   default.payment.next.month : Default payment (1=yes, 0=no)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "clients_df.nunique()\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in clients_df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",clients_df[i].nunique())"
      ],
      "metadata": {
        "id": "6Da47VrJgp4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations:\n",
        "\n",
        "*   We are focusing on several key columns of our dataset, including 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', and 'PAY_AMT' as they contain a wealth of information.\n",
        "*   By utilizing these features, we plan to create a classification model and implement various classification algorithms.\n",
        "\n"
      ],
      "metadata": {
        "id": "MMSUxir_gt-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***EDA***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Renaming Features"
      ],
      "metadata": {
        "id": "oWO6nd5bh0Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming complex columns name for the sake of simplicity    **(Not a necessary step to do)**\n",
        "# Changing inconsistent column names \"PAY_0\" to 'PAY_1', 'default.payment.next.month'to 'DP_NEXT_MONTH'\n",
        "clients_df.rename(columns={'PAY_0':'PAY_1','default payment next month':'DP_NEXT_MONTH'},inplace = True)\n",
        "clients_df.columns"
      ],
      "metadata": {
        "id": "Y0z2gqCWh2TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Column: 'DP_NEXT_MONTH'"
      ],
      "metadata": {
        "id": "8rhgOAJPiAhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,2, figsize=(12,4))\n",
        "\n",
        "# Univariate analysis\n",
        "# Count Plot of Default Payment\n",
        "count = sns.countplot(data=clients_df, x='DP_NEXT_MONTH', ax=ax[0])\n",
        "count.set_title('Count Plot of Default Payment')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in count.patches:\n",
        "  count.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))\n",
        "\n",
        "# Univariate analysis\n",
        "# Percentage of Default and Non-Default Payment\n",
        "pie = clients_df['DP_NEXT_MONTH'].value_counts().plot(kind='pie',autopct=\"%1.1f%%\",labels=['Not Defaulted','Defaulted'], ax=ax[1])\n",
        "pie.set_title('Percentage of Default and Non-Default Payment')"
      ],
      "metadata": {
        "id": "YrcVp_t5iChg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    We can observe from the graphs that the number of default payments in the data is low in number compared to the number of not default payments. The count of default payments is 6636 while the count of not default payments is 23364.\n",
        "*   By percentage 22.1% of customers defaulted on their payment whereas 77.9% of customers do not default on their credit card payment.\n",
        "\n",
        "\n",
        "*   We can say that the data is highly imbalanced which we need to balance. We will do that in the feature engineering step.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KceDemSiiIly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Column: 'LIMIT_BAL'"
      ],
      "metadata": {
        "id": "9TXiN56IilVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,4, figsize=(15,5))\n",
        "\n",
        "# Distribution analysis of Limit Balance\n",
        "hist = sns.histplot(clients_df['LIMIT_BAL'],bins=10, ax=ax[0])\n",
        "hist.set_title('Distribution Plot of Limit Balance', size=15)\n",
        "\n",
        "# Bi-variate analysis\n",
        "# Limit Balance Vs Default Payment\n",
        "hist = sns.histplot(data=clients_df, x='LIMIT_BAL', hue='DP_NEXT_MONTH',bins=10, ax=ax[1])\n",
        "hist.set_title('Limit Balance Vs Default Payment', size=15)\n",
        "\n",
        "# Multi-variate analysis\n",
        "# Limit Balance Vs SEX\n",
        "bar = sns.barplot(data=clients_df, x='SEX', y='LIMIT_BAL',hue='DP_NEXT_MONTH', ax=ax[2])\n",
        "bar.set_title('Limit Balance Vs SEX', size=15)\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in bar.patches:\n",
        "    bar.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "# Gender (1=male, 2=female)\n",
        "bar.set_xticklabels(['Male', 'Female'])\n",
        "\n",
        "# Bi-variate analysis\n",
        "# Limit Balance Vs EDUCATION\n",
        "bar = sns.barplot(data=clients_df, x='EDUCATION', y='LIMIT_BAL', ax=ax[3])\n",
        "bar.set_title('Limit Balance Vs EDUCATION', size=15)\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in bar.patches:\n",
        "    bar.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "# EDUCATION (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
        "bar.set_xticklabels(['Unknown','Graduate School', 'University', 'High School', 'Others', 'Unknown', 'Unknown'])\n",
        "\n",
        "# Set x-ticks rotation to 90 degrees\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mF1YBi4CitfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    Most of the customers get up to 2 lakhs of credit limit balance.\n",
        "\n",
        "*   \n",
        "There appears to be a negative correlation between the percentage of defaults and credit limit.\n",
        "*   On average females gets more limit than males. The female has an average of 170k while the male has an average of 163k.\n",
        "\n",
        "\n",
        "*   Graph also indicates that higher education means a higher credit limit. We have to categorize all the unknown education categories as one.\n",
        "\n"
      ],
      "metadata": {
        "id": "6qEnfZqri4EC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Column: 'SEX'"
      ],
      "metadata": {
        "id": "hjPRFLujjP0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Univariate analysis\n",
        "count = sns.countplot(clients_df['SEX'], ax=ax[0])\n",
        "count.set_title('Count Plot of Gender', size=15)\n",
        "\n",
        "# adding value count on the top of the bar\n",
        "for p in count.patches:\n",
        "    count.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "count.set_xticks([0, 1])  # Set the tick locations for Male and Female\n",
        "count.set_xticklabels(['Male', 'Female'])  # Set the labels for the tick locations\n",
        "\n",
        "# Bivariate analysis\n",
        "# SEX Vs Default Payment\n",
        "bar = sns.barplot(data=clients_df, x='SEX', y='DP_NEXT_MONTH', ax=ax[1])\n",
        "bar.set_title('Proportion of Default Payment in Different Gender', size=15)\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "bar.set_xticks([0, 1])  # Set the tick locations for Male and Female\n",
        "bar.set_xticklabels(['Male', 'Female'])  # Set the labels for the tick locations\n",
        "\n",
        "# adding value count on the top of the bar\n",
        "for p in bar.patches:\n",
        "    bar.annotate(format(p.get_height() * 100, '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center')\n",
        "\n",
        "# Multivariate analysis\n",
        "# SEX Vs Default Payment with Limit Balance\n",
        "bar = sns.barplot(data=clients_df, x='SEX', y='LIMIT_BAL', hue='DP_NEXT_MONTH', ax=ax[2])\n",
        "bar.set_title('SEX Vs Default Payment with Limit Balance', size=15)\n",
        "\n",
        "# adding value count on the top of the bar\n",
        "for p in bar.patches:\n",
        "    bar.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "bar.set_xticks([0, 1])  # Set the tick locations for Male and Female\n",
        "bar.set_xticklabels(['Male', 'Female'])  # Set the labels for the tick locations\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ZIkya9DrXHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "\n",
        "*   There are 18112 females and 11888 males in the data set.\n",
        "\n",
        "*   About 24% percent of males defaulted and about 21% of the female defaulted.\n",
        "*   Number of males who defaulted is less in number but the proportion is greater. It might be possible because males have fewer credit limits on their credit cards as we can see in the graph too.\n",
        "\n"
      ],
      "metadata": {
        "id": "1VD7NyITjYrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Column: 'EDUCATION'"
      ],
      "metadata": {
        "id": "yOWHX_uhrwn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Univariate analysis\n",
        "count = sns.countplot(clients_df['EDUCATION'], ax=ax[0])\n",
        "count.set_title('Count Plot of Education')\n",
        "\n",
        "# adding value count on the top of the bar\n",
        "for p in count.patches:\n",
        "    count.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "education_labels = ['Unknown', 'Graduate School', 'University', 'High School', 'Others', 'Unknown', 'Unknown']\n",
        "count.set_xticks(range(len(education_labels)))  # Set the tick locations\n",
        "count.set_xticklabels(education_labels, rotation=90)  # Set the labels with rotation\n",
        "\n",
        "# Bivariate analysis\n",
        "# EDUCATION Vs Default Payment\n",
        "bar = sns.barplot(data=clients_df, x='EDUCATION', y='DP_NEXT_MONTH', ax=ax[1])\n",
        "bar.set_title('Proportion of Default Payment in Different Education Level')\n",
        "\n",
        "# adding value count on the top of the bar\n",
        "for p in bar.patches:\n",
        "    bar.annotate(format(p.get_height() * 100, '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "bar.set_xticks(range(len(education_labels)))  # Set the tick locations\n",
        "bar.set_xticklabels(education_labels, rotation=90)  # Set the labels with rotation\n",
        "\n",
        "# Multivariate analysis\n",
        "# EDUCATION Vs Default Payment with SEX\n",
        "bar = sns.barplot(data=clients_df, x='EDUCATION', y='DP_NEXT_MONTH', hue='SEX', ax=ax[2])\n",
        "bar.set_title('Education Vs Default Payment with SEX')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "bar.set_xticks(range(len(education_labels)))  # Set the tick locations\n",
        "bar.set_xticklabels(education_labels, rotation=90)  # Set the labels with rotation\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9qWwldMVshOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "*   10,585 people with degrees from graduate schools; 14,030 individuals with college degrees; 4,917 people with high school degrees. Count of customers who has completed University is most in numbers followed by Graduate School and High School.\n",
        "\n",
        "*   With the rise in education level proportion of default decreases. We can see that Graduate School education level customers defaulted by 19% while University Education level customer default percentage is 24% followed by High School with 25%.\n",
        "*   In almost all education levels females have less default percentage than males.\n"
      ],
      "metadata": {
        "id": "e_taMwb5snib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Column: 'MARRIAGE'"
      ],
      "metadata": {
        "id": "7Wzg0nOJs8f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Univariate analysis\n",
        "count = sns.countplot(clients_df['MARRIAGE'], ax=ax[0])\n",
        "count.set_title('Count Plot of Marriage')\n",
        "\n",
        "# adding value count on the top of the bar\n",
        "for p in count.patches:\n",
        "    count.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "marriage_labels = ['Others', 'Married', 'Single', 'Divorce']\n",
        "count.set_xticks(range(len(marriage_labels)))  # Set the tick locations\n",
        "count.set_xticklabels(marriage_labels, rotation=90)  # Set the labels with rotation\n",
        "\n",
        "# Bivariate analysis\n",
        "# MARRIAGE Vs Default Payment\n",
        "bar = sns.barplot(data=clients_df, x='MARRIAGE', y='DP_NEXT_MONTH', ax=ax[1])\n",
        "bar.set_title('Proportion of Default Payment in Different Marital Status')\n",
        "\n",
        "# adding value count on the top of the bar\n",
        "for p in bar.patches:\n",
        "    bar.annotate(format(p.get_height() * 100, '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "bar.set_xticks(range(len(marriage_labels)))  # Set the tick locations\n",
        "bar.set_xticklabels(marriage_labels, rotation=90)  # Set the labels with rotation\n",
        "\n",
        "# Multivariate analysis\n",
        "# MARRIAGE Vs Default Payment with SEX\n",
        "bar = sns.barplot(data=clients_df, x='MARRIAGE', y='DP_NEXT_MONTH', hue='SEX', ax=ax[2])\n",
        "bar.set_title('Marital Status Vs Default Payment with SEX')\n",
        "\n",
        "# Assign labels to the x-axis categories\n",
        "bar.set_xticks(range(len(marriage_labels)))  # Set the tick locations\n",
        "bar.set_xticklabels(marriage_labels, rotation=90)  # Set the labels with rotation\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aay3aPv-uTD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "*   \n",
        "\n",
        "    13,659 people who are married; 15,964 single people; 323 people who divorced; 54 people who are considered \"others.\" Count of customers who are single is most in numbers followed by married and divorced.\n",
        "\n",
        "*   The number of defaults appears to be highest among divorced people (26%) and lowest among single people (21%) (ignoring \"Others\" due to the low count).\n",
        "*   In all Marital status females have less default percentage than males.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZFqcbXLiuV0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column: 'AGE'"
      ],
      "metadata": {
        "id": "r8a7O0PdvGjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,2, figsize=(12,5))\n",
        "\n",
        "# Distribution analysis of Age\n",
        "hist = sns.histplot(clients_df['AGE'],bins=6, ax=ax[0])\n",
        "hist.set_title('Histogram Plot of Age', size=15)\n",
        "\n",
        "# Bi-variate analysis\n",
        "# Age Vs Default Payment\n",
        "hist = sns.histplot(data=clients_df, x='AGE', hue='DP_NEXT_MONTH', bins=6, ax=ax[1])\n",
        "hist.set(title='Age Vs Default Payment',ylabel='Default Payments Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RHo_zFbvvP4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "\n",
        "*   With the increase in age the count of customers decreases. Most of the customers belong to the 20-30 year age group followed by the 30-40 age group.\n",
        "*   With an increase in the age group the count of default payments decreases.\n",
        "\n"
      ],
      "metadata": {
        "id": "6e1YF7-kvhJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Columns: 'Payment History'"
      ],
      "metadata": {
        "id": "FPwW98IbvvFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the dataset to transform the categorical columns to rows\n",
        "melted_df = clients_df.melt(value_vars=['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'], var_name='Category', value_name='Value')\n",
        "\n",
        "# Group the data by category and value and count the number of occurrences\n",
        "grouped_df = melted_df.groupby(['Category', 'Value']).size().reset_index(name='Count')\n",
        "\n",
        "# Create a dictionary to rename old values to new values\n",
        "# (-2=no consumption, -1=pay duly, 0=the use of revolving credit, 1=payment delay for one month, 2=payment delay for two months,\n",
        "# … 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
        "value_map = {-2:'no consumption', -1:'paid', 0:'revolving credit', 1:'1 month delay', 2:'2 month delay', 3:'3 month delay',\n",
        "              4:'4 month delay', 5:'5 month delay', 6:'6 month delay', 7:'7 month delay', 8:'8 month delay', 9:'9 month and more delay'}\n",
        "\n",
        "# Replace the old values with the new values\n",
        "grouped_df['Value'] = grouped_df['Value'].replace(value_map)"
      ],
      "metadata": {
        "id": "12jPZvQZvz3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# Univariate analysis\n",
        "bar = sns.barplot(data=grouped_df, x='Category', y='Count',palette='pastel', hue='Value')\n",
        "bar.set_title('Bar Plot of Payment History')\n",
        "lgd = plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-qL6RQ_hv3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "*   \n",
        "\n",
        "    In every month's payment history, most customers are from revolving credit followed by paid\n",
        "*   Customers with payment delay in all the payment history have the most number in 2-month payment delay means a 2-month payment delay is a critical sign of the default of the payment.\n",
        "\n"
      ],
      "metadata": {
        "id": "6ySTBp88v84F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Columns: 'Bill Amounts'"
      ],
      "metadata": {
        "id": "BJMPjGf6wIai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating few columns to consolidate all the bill amounts\n",
        "clients_df['Sum_all_bill'] = clients_df['BILL_AMT1']+clients_df['BILL_AMT2']+clients_df['BILL_AMT3']+\\\n",
        "                             clients_df['BILL_AMT4']+clients_df['BILL_AMT5']+clients_df['BILL_AMT6']\n",
        "\n",
        "clients_df['Avg_bill'] =    (clients_df['BILL_AMT1']+clients_df['BILL_AMT2']+clients_df['BILL_AMT3']+\\\n",
        "                             clients_df['BILL_AMT4']+clients_df['BILL_AMT5']+clients_df['BILL_AMT6'])/6"
      ],
      "metadata": {
        "id": "-5w6S5XrwN9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,3, figsize=(15,5))\n",
        "\n",
        "# Distribution analysis of Bill Amount\n",
        "hist = sns.histplot(clients_df['Sum_all_bill'],bins=11, ax=ax[0])\n",
        "hist.set_title('Distribution Plot of Bill Amount', size=15)\n",
        "\n",
        "# Bi-variate analysis\n",
        "# Bill amount Vs Default Payment Count\n",
        "hist = sns.histplot(data=clients_df, x='Avg_bill', hue='DP_NEXT_MONTH',bins=11, ax=ax[1])\n",
        "hist.set_title('Bill amount Vs Default Payment Count', size=15)\n",
        "\n",
        "# Bi-variate analysis\n",
        "# Bill amount Vs Proportion of Default Payment\n",
        "hist = sns.histplot(data=clients_df, x='Avg_bill', hue='DP_NEXT_MONTH', bins=11, multiple='fill', stat='probability', ax=ax[2])\n",
        "hist.set_title('Bill amount Vs Proportion of Default Payment', size=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nJVBErW3wUgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "*   \n",
        "\n",
        "    In all the bill amounts there are some negative bill amount records means the bill amount value is less than zero.\n",
        "*   Most of the defaults are from customers who have negative and up to 2 lakh bill amount on an average in the last 6 months.\n",
        "\n",
        "*   But if we compare the bill amount with default payment, the proportion of default payment rises with the rise in the average bill amount.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nz6N4Nu3wWo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Columns: 'Pay Amounts'"
      ],
      "metadata": {
        "id": "mbw6wueswvtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating few columns to consolidate all the bill amounts\n",
        "clients_df['Sum_all_pay_amount'] = clients_df['PAY_AMT1']+clients_df['PAY_AMT2']+clients_df['PAY_AMT3']+\\\n",
        "                             clients_df['PAY_AMT4']+clients_df['PAY_AMT5']+clients_df['PAY_AMT6']\n",
        "\n",
        "clients_df['Avg_pay_amount'] =    (clients_df['PAY_AMT1']+clients_df['PAY_AMT2']+clients_df['PAY_AMT3']+\\\n",
        "                             clients_df['PAY_AMT4']+clients_df['PAY_AMT5']+clients_df['PAY_AMT6'])/6"
      ],
      "metadata": {
        "id": "3jEQNvtLw2HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,3, figsize=(15,5))\n",
        "\n",
        "# Distribution analysis of Pay Amount\n",
        "hist = sns.histplot(clients_df['Sum_all_pay_amount'],bins=11, ax=ax[0])\n",
        "hist.set_title('Distribution Plot of Pay Amount', size=15)\n",
        "\n",
        "# Bi-variate analysis\n",
        "# Pay amount Vs Default Payment Count\n",
        "hist = sns.histplot(data=clients_df, x='Avg_pay_amount', hue='DP_NEXT_MONTH',bins=11, ax=ax[1])\n",
        "hist.set_title('Pay Amount Vs Default Payment Count', size=15)\n",
        "\n",
        "# Bi-variate analysis\n",
        "# Pay amount Vs Proportion of Default Payment\n",
        "hist = sns.histplot(data=clients_df, x='Avg_pay_amount', hue='DP_NEXT_MONTH', bins=11, multiple='fill', stat='probability', ax=ax[2])\n",
        "hist.set_title('Pay Amount Vs Proportion of Default Payment', size=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aG--nE8Dw6Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "*   In all the pay amounts most of the paid amount is up to 50000\n",
        "\n",
        "*   We have seen bill amounts up to 2 lacks but the pay amount is not averaged up to 2 lakh which is obvious because default payment occurs when the customer does not pay the credit card bill.\n",
        "*   If we compare the pay amount with the default payment, the proportion of default payment decreases with the rise in the payment amount.\n",
        "\n"
      ],
      "metadata": {
        "id": "yUdU5OtQw7-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Cleaning***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Duplicate Values**"
      ],
      "metadata": {
        "id": "LtQXOd-tVDvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counting duplicate values\n",
        "clients_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "jfBVpdlaVMQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no duplicate records.\n"
      ],
      "metadata": {
        "id": "uHSFE-jRVPn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Missing Values**"
      ],
      "metadata": {
        "id": "P5MDKExbVayq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(clients_df.isnull().sum())"
      ],
      "metadata": {
        "id": "AuT6zazTVfGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that there is no missing values."
      ],
      "metadata": {
        "id": "ghDBdavBVlGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Skewness**"
      ],
      "metadata": {
        "id": "yU2fgnMDVzKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical summary\n",
        "clients_df.describe().T"
      ],
      "metadata": {
        "id": "K5g8UUa5V4iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "As can be seen in the statistical summary for numerical features, there is a significant difference between the 75% percentile and maximum value, indicating that the dataset contains skewness and outliers.\n"
      ],
      "metadata": {
        "id": "pt2AajyKV9AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = []\n",
        "categorical_features = []\n",
        "\n",
        "# splitting features into numeric and categoric.\n",
        "'''\n",
        "If feature has more than 15 categories we will consider it\n",
        "as numerical_features, remaining features will be added to categorical_features.\n",
        "'''\n",
        "for col in clients_df.columns:\n",
        "  if clients_df[col].nunique() > 15:\n",
        "    numerical_features.append(col)\n",
        "  else:\n",
        "    categorical_features.append(col)\n",
        "\n",
        "print(f'Numerical Features : {numerical_features}')\n",
        "print(f'Categorical Features : {categorical_features}')"
      ],
      "metadata": {
        "id": "EoURGIsUWANq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# figsize\n",
        "plt.figure(figsize=(15,12))\n",
        "# title\n",
        "plt.suptitle('Data Distibution of Numerical Features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i,col in enumerate(numerical_features):\n",
        "  plt.subplot(4, 5, i+1)                       # subplots 4 rows, 5 columns\n",
        "\n",
        "  # dist plots\n",
        "  sns.distplot(clients_df[col])\n",
        "  # x-axis label\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "DME4RUVeWHSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "*   For numerical features, we can see that the majority of distributions are right-skewed. The distribution of all the bill amounts and pay amounts is highly skewed to the right. It demonstrates that these columns have many outliers.\n",
        "*   Some of the variables can get a normal distribution when outliers are removed. As a result, it appears that outliers should be removed before the transformation. First, we will get rid of outliers, and then we check to see if we need to use the transformation technique again.\n",
        "\n"
      ],
      "metadata": {
        "id": "i6RIJncUWMPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treating Outliers**"
      ],
      "metadata": {
        "id": "KxAbGxR7WYzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# figsize\n",
        "plt.figure(figsize=(15,12))\n",
        "# title\n",
        "plt.suptitle('Outlier Analysis of Numerical Features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i,col in enumerate(numerical_features):\n",
        "  plt.subplot(4, 5, i+1)            # subplot of 4 rows and 5 columns\n",
        "\n",
        "  # countplot\n",
        "  sns.boxplot(clients_df[col])\n",
        "  # x-axis label\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "0MbRRy47Wd7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "\n",
        "*   Outliers are visible in the all the bill amounts features and all the pay amounts features, and 'LIMIT_BAL' columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "o2xfno1-Wm3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clipping Method: In this method, we set a cap on our outliers data, which means that if a value is higher than or lower than a certain threshold, all values will be considered outliers. This method replaces values that fall outside of a specified range with either the minimum or maximum value within that range."
      ],
      "metadata": {
        "id": "EMBgdyP-WvR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to replace the datapoints with upper and lower bound of all the outliers\n",
        "\n",
        "def clip_outliers(clients_df):\n",
        "    for col in clients_df[numerical_features]:\n",
        "        # using IQR method to define range of upper and lower limit.\n",
        "        q1 = clients_df[col].quantile(0.25)\n",
        "        q3 = clients_df[col].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "        # replacing the outliers with upper and lower bound\n",
        "        clients_df[col] = clients_df[col].clip(lower_bound, upper_bound)\n",
        "    return clients_df"
      ],
      "metadata": {
        "id": "hc6O8i3vWzKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the function to treat outliers\n",
        "clients_df = clip_outliers(clients_df)"
      ],
      "metadata": {
        "id": "uUY2K-ZXW20a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the boxplot after outlier treatment\n",
        "\n",
        "# figsize\n",
        "plt.figure(figsize=(15,12))\n",
        "# title\n",
        "plt.suptitle('Outlier Analysis of Numerical Features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i,col in enumerate(numerical_features):\n",
        "  plt.subplot(4, 5, i+1)            # subplot of 4 rows and 5 columns\n",
        "\n",
        "  # countplot\n",
        "  sns.boxplot(clients_df[col])\n",
        "  # x-axis label\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "xCVEMy6hW7gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for distribution after treating outliers.\n",
        "\n",
        "# figsize\n",
        "plt.figure(figsize=(15,12))\n",
        "# title\n",
        "plt.suptitle('Data Distibution of Numerical Features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i,col in enumerate(numerical_features):\n",
        "  plt.subplot(4, 5, i+1)                       # subplots 4 rows, 5 columns\n",
        "\n",
        "  # dist plots\n",
        "  sns.distplot(clients_df[col])\n",
        "  # x-axis label\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "WzaiGBBnWJwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We can also observe some shifts in the distribution of the data after treating outliers. Some of the data were skewed before handling outliers, but after doing so, the features almost follow the normal distribution. Therefore, we are not utilizing the numerical feature transformation technique.\n",
        "\n"
      ],
      "metadata": {
        "id": "rRXcn0T_XDyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Hypothesis Testing"
      ],
      "metadata": {
        "id": "006JosINtGYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Based on chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through codes and statistical testings.\n",
        "\n",
        "Creating a class to calculate mean, median, variance, P value and all other metrics required for the calculation of hypothesis testing.\n"
      ],
      "metadata": {
        "id": "JrgtrCb-tRX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Parameter Class\n",
        "class findz:\n",
        "  def proportion(self,sample,hyp,size):\n",
        "    return (sample - hyp)/math.sqrt(hyp*(1-hyp)/size)\n",
        "  def mean(self,hyp,sample,size,std):\n",
        "    return (sample - hyp)*math.sqrt(size)/std\n",
        "  def varience(self,hyp,sample,size):\n",
        "    return (size-1)*sample/hyp\n",
        "\n",
        "variance = lambda x : sum([(i - np.mean(x))**2 for i in x])/(len(x)-1)\n",
        "zcdf = lambda x: norm(0,1).cdf(x)\n",
        "# Creating a function for getting P value\n",
        "def p_value(z,tailed,t,hypothesis_number,df,col):\n",
        "  if t!=\"true\":\n",
        "    z=zcdf(z)\n",
        "    if tailed=='l':\n",
        "      return z\n",
        "    elif tailed == 'r':\n",
        "      return 1-z\n",
        "    elif tailed == 'd':\n",
        "      if z>0.5:\n",
        "        return 2*(1-z)\n",
        "      else:\n",
        "        return 2*z\n",
        "    else:\n",
        "      return np.nan\n",
        "  else:\n",
        "    z,p_value=stats.ttest_1samp(df[col],hypothesis_number)\n",
        "    return p_value\n",
        "\n",
        "\n",
        "# Conclusion about the P - Value\n",
        "def conclusion(p):\n",
        "  significance_level = 0.05\n",
        "  if p>significance_level:\n",
        "    return f\"Failed to reject the Null Hypothesis for p = {p}.\"\n",
        "  else:\n",
        "    return f\"Null Hypothesis rejected Successfully for p = {p}\"\n",
        "\n",
        "# Initializing the class\n",
        "findz = findz()"
      ],
      "metadata": {
        "id": "On6B4B-AtME_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Men not defaulting are more than or equal to 40 years of AGE\n",
        "2.   Customers defaulting have limit balance less than 100000\n",
        "\n",
        "1.   Customers defaulting have total last bill amount of 50000.\n",
        "\n",
        "In all of the hypothesis tests in this notebook, we will use a significance level of α = 0.05\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w__ecTR7tXud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothetical Statement - 1**\n",
        "\n",
        "Men not defaulting are more than or equal to 40 years of AGE.\n",
        "\n",
        "\n",
        "\n",
        "State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "\n",
        "Null Hypothesis: N = 40\n",
        "\n",
        "Alternate Hypothesis : N < 40\n",
        "\n",
        "Test Type: Left Tailed Test\n"
      ],
      "metadata": {
        "id": "R6unHwmDtxoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# SEX:\n",
        "# 1 = male; 2 = female\n",
        "\n",
        "# DP_NEXT_MONTH:\n",
        "# 0 = non-default; 1 = default\n",
        "\n",
        "hypo_1 = clients_df[(clients_df['SEX']==1) & (clients_df[\"DP_NEXT_MONTH\"]==0)]\n",
        "\n",
        "# Getting the required parameter values for hypothesis testing\n",
        "hypothesis_number = 40\n",
        "sample_mean = hypo_1[\"AGE\"].mean()\n",
        "size = len(hypo_1)\n",
        "std=(variance(hypo_1[\"AGE\"]))**0.5"
      ],
      "metadata": {
        "id": "UtRj-yDktzW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Z value\n",
        "z = findz.mean(hypothesis_number,sample_mean,size,std)\n",
        "\n",
        "# Getting P - Value\n",
        "p = p_value(z=z,tailed='l',t=\"false\",hypothesis_number=hypothesis_number,df=hypo_1,col=\"AGE\")\n",
        "\n",
        "# Getting Conclusion\n",
        "print(conclusion(p))"
      ],
      "metadata": {
        "id": "JzBgxv9BtGAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which statistical test have you done to obtain P-Value?\n",
        "\n",
        "\n",
        "I used Z-Test as the statistical testing to get the P-Value, and the results showed that the null hypothesis could not be rejected, and male customers who didn't default were over 40 years old."
      ],
      "metadata": {
        "id": "gMjcvH0LuFxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Oc7HT6GWuQYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing code of hist plot for required columns to know the data distibution\n",
        "\n",
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "feature= (hypo_1[\"AGE\"])\n",
        "sns.distplot(hypo_1[\"AGE\"])\n",
        "ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nvFvirEMuRdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_median_difference=hypo_1[\"AGE\"].mean()- hypo_1[\"AGE\"].median()\n",
        "print(\"Mean Median Difference is :-\",mean_median_difference)"
      ],
      "metadata": {
        "id": "brCUcss9uNE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The figure demonstrates that the mean and median are roughly equivalent; the difference between them is 1.38 (less than 10). As a result, the distribution is normal. I have used Z-Test directly as a result.\n",
        "\n",
        "We have failed to reject the null hypothesis that N < 40\n"
      ],
      "metadata": {
        "id": "X-BS88mhTl9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothetical Statement - 2**\n",
        "\n",
        "Customers defaulting have limit balance less than 100000"
      ],
      "metadata": {
        "id": "Qf7xoS2uTrl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "\n",
        "Null Hypothesis: N = 100000\n",
        "\n",
        "Alternate Hypothesis : N > 100000\n",
        "\n",
        "Test Type: Right Tailed Test\n"
      ],
      "metadata": {
        "id": "ZjSEgFObT8BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# DP_NEXT_MONTH:\n",
        "# 0 = non-default; 1 = default\n",
        "hypo_2=clients_df[(clients_df[\"DP_NEXT_MONTH\"]==1)]\n",
        "\n",
        "# Getting the required parameter values for hypothesis testing\n",
        "hypothesis_number = 100000\n",
        "sample_mean = hypo_2[\"LIMIT_BAL\"].mean()\n",
        "size = len(hypo_2)\n",
        "std=(variance(hypo_2[\"LIMIT_BAL\"]))**0.5"
      ],
      "metadata": {
        "id": "8I2mLjT-UCyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Z value\n",
        "z = findz.mean(hypothesis_number,sample_mean,size,std)\n",
        "\n",
        "# Getting P - Value\n",
        "p = p_value(z=z,tailed='r',t=\"true\",hypothesis_number=hypothesis_number,df=hypo_2,col=\"LIMIT_BAL\")\n",
        "\n",
        "# Getting Conclusion\n",
        "print(conclusion(p))"
      ],
      "metadata": {
        "id": "v_USxY__UFvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dxp3xod5UMjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used T-Test as the statistical testing to get the P-Value, and the result showed that the null hypothesis was wrong and that customers who defaulted had a limit balance of less than 100,000."
      ],
      "metadata": {
        "id": "uSdLAXiVUN98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "N75pJLiiUWXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing code of hist plot for required columns to know the data distibution\n",
        "\n",
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "feature= (hypo_2[\"LIMIT_BAL\"])\n",
        "sns.distplot(hypo_2[\"LIMIT_BAL\"])\n",
        "ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wo7TFrvhUFh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_median_difference=hypo_2[\"LIMIT_BAL\"].mean()- hypo_2[\"LIMIT_BAL\"].median()\n",
        "print(\"Mean Median Difference is :-\",mean_median_difference)"
      ],
      "metadata": {
        "id": "HxiaXlUbUeYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The graph above demonstrates that the median is greater than the mean above 10,000. As a result, the distribution is positively skewed. Z-Test cannot be used with skewed data.\n",
        "\n",
        "For small studies, non-parametric tests are most useful. In large studies, the use of non-parametric tests may answer the wrong question, causing readers confusion. Even with heavily skewed data, t-tests and the confidence intervals that go along with them should be used in studies with large sample sizes.\n",
        "\n",
        "Therefore, the T-test can yield better results for skewed data. So, I used the t-test.\n"
      ],
      "metadata": {
        "id": "vPQDSOW7Uh_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothetical Statement - 3\n",
        "\n",
        "Customers defaulting have total last bill amount of 50000."
      ],
      "metadata": {
        "id": "qT5wyYdWUpP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "\n",
        "Null Hypothesis: N = 50000\n",
        "\n",
        "Alternate Hypothesis : N != 50000\n",
        "\n",
        "Test Type: Two Tailed test\n"
      ],
      "metadata": {
        "id": "1hSjKHGRUtJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# DP_NEXT_MONTH:\n",
        "# 0 = non-default; 1 = default\n",
        "hypo_3=clients_df[(clients_df[\"DP_NEXT_MONTH\"]==1)]\n",
        "\n",
        "# Getting the required parameter values for hypothesis testing\n",
        "hypothesis_number = 50000\n",
        "sample_mean = hypo_3[\"BILL_AMT1\"].mean()\n",
        "size = len(hypo_3)\n",
        "std=(variance(hypo_3[\"BILL_AMT1\"]))**0.5"
      ],
      "metadata": {
        "id": "bfV1uVgqUznA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Z value\n",
        "z = findz.mean(hypothesis_number,sample_mean,size,std)\n",
        "\n",
        "# Getting P - Value\n",
        "p = p_value(z=z,tailed='d',t=\"true\",hypothesis_number=hypothesis_number,df=hypo_3,col=\"BILL_AMT1\")\n",
        "\n",
        "# Getting Conclusion\n",
        "print(conclusion(p))"
      ],
      "metadata": {
        "id": "lfLf3soLU21k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "KH4zCitwU729"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used T-Test as the statistical testing to get the P-Value, and the result showed that the null hypothesis could not be rejected, so the statement that \"Customers defaulted with a total last bill amount of 50,000\" was correct."
      ],
      "metadata": {
        "id": "R0gfijf9U_uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "w3s0qfV1VD8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing code of hist plot for required columns to know the data distibution\n",
        "\n",
        "fig=plt.figure(figsize=(9,6))\n",
        "ax=fig.gca()\n",
        "feature= (hypo_3[\"BILL_AMT1\"])\n",
        "sns.distplot(hypo_3[\"BILL_AMT1\"])\n",
        "ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BVWLPIa2U851"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_median_difference=hypo_3[\"BILL_AMT1\"].median()- hypo_3[\"BILL_AMT1\"].mean()\n",
        "print(\"Mean Median Difference is :-\",mean_median_difference)"
      ],
      "metadata": {
        "id": "tcY7REQqVMP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The graph above demonstrates that the median is greater than the mean above 10,000. As a result, the distribution is positively skewed Z-Test cannot be used with skewed data.\n",
        "\n",
        "For small studies, nonparametric tests are most useful. In large studies, the use of non-parametric tests may answer the wrong question, causing readers confusion. Even with heavily skewed data, t-tests and the confidence intervals that go along with them should be used in studies with large sample sizes.\n",
        "\n",
        "Therefore, the T-test can yield better results for skewed data. So, I used the t-test.\n"
      ],
      "metadata": {
        "id": "xnv9-rE3VQUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Feature Engineering"
      ],
      "metadata": {
        "id": "-u2UzT5Fj7uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.1 Feature Manipulation**"
      ],
      "metadata": {
        "id": "QUTHtXN_kHfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copying this data to protect the work done till now\n",
        "df_feature = clients_df.copy()"
      ],
      "metadata": {
        "id": "FbCwpmIckLc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = []\n",
        "categorical_features = []\n",
        "\n",
        "# splitting features into numeric and categoric.\n",
        "'''\n",
        "If feature has more than 15 categories we will consider it\n",
        "as numerical_features, remaining features will be added to categorical_features.\n",
        "'''\n",
        "for col in df_feature.columns:\n",
        "  if df_feature[col].nunique() > 15:\n",
        "    numerical_features.append(col)\n",
        "  else:\n",
        "    categorical_features.append(col)\n",
        "\n",
        "print(f'Numerical Features : {numerical_features}')\n",
        "print(f'Categorical Features : {categorical_features}')"
      ],
      "metadata": {
        "id": "y-bdaVL-kbj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.1 Bill_AMT"
      ],
      "metadata": {
        "id": "al6ldx5Mk-bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative bill amounts are not possible in a credit card dataset as a bill represents the amount of money that the credit card holder owes to the bank. It is always a positive value. However, negative values can occur due to data entry errors or other issues. Hence we are dropping all negative bill amount instances."
      ],
      "metadata": {
        "id": "46ey45pBlDxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_feature = df_feature[df_feature['BILL_AMT1'] >= 0]"
      ],
      "metadata": {
        "id": "pkq05smtlIlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.2 EDUCATION"
      ],
      "metadata": {
        "id": "6MP8dQ7ykpS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The education column has a lot of unknown sub-categories so combining them into one sub-category."
      ],
      "metadata": {
        "id": "WEAp0pGllLPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the value counts of each sub-category of EDUCATION\n",
        "df_feature['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "UmKoGbNilQ4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lambda Function can be used to convert all unknown sub-category as one unknown sub-category\n",
        "df_feature['EDUCATION'] = df_feature['EDUCATION'].apply(lambda x: 4 if x in [0, 5, 6] else x)"
      ],
      "metadata": {
        "id": "kX_9Me0XlXIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cheking the result\n",
        "df_feature['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "dHqzskmLla6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2 Encoding**"
      ],
      "metadata": {
        "id": "C-O1WV_llfvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each categorical variable.\n",
        "for i in categorical_features:\n",
        "  print(\"No. of unique values in\",i,\"is\",df_feature[i].nunique())"
      ],
      "metadata": {
        "id": "TXjCFFZelnxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping our target variable from categorical features list\n",
        "categorical_features.remove('DP_NEXT_MONTH')"
      ],
      "metadata": {
        "id": "4wGLtJYelqda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data type of each feature\n",
        "df_feature.info()"
      ],
      "metadata": {
        "id": "wsHCocMeltjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation\n",
        "\n",
        "*   All the categorical columns have already been encoded, we just need to convert the categorical column data type as an object or category.\n",
        "\n"
      ],
      "metadata": {
        "id": "CEpQP33vlyIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cast values in the categorical columns as type str.                 # can use astype('category') too.\n",
        "df_feature[categorical_features] = df_feature[categorical_features].astype(str)\n",
        "\n",
        "# checking the result\n",
        "df_feature.dtypes"
      ],
      "metadata": {
        "id": "oFcJ1snxl7C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.3 Correlation Coefficient and Heatmap**"
      ],
      "metadata": {
        "id": "SwfvFqklmCSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting correlation heatmap\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.heatmap(df_feature.corr(), annot=True)"
      ],
      "metadata": {
        "id": "JxigX5MgmHBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find and remove correlated features\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()                                           # Set of all the names of correlated features\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold:        # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]               # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr"
      ],
      "metadata": {
        "id": "R6j_vV-PmQS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the highly correlated features\n",
        "correlation(df_feature, 0.7)          # setting threshold of 0.7"
      ],
      "metadata": {
        "id": "H7gqMXR-mWxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# droping columns due to multi-collinearity\n",
        "\n",
        "df_feature.drop(['Avg_bill','Avg_pay_amount','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','Sum_all_bill'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "SQtyJA6pmai8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting correlation heatmap again\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.heatmap(df_feature.corr(), annot=True)"
      ],
      "metadata": {
        "id": "SCqKX2zTme9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.4 Feature Selection"
      ],
      "metadata": {
        "id": "vi37DeUFmkRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Feature selection is a technique in machine learning where you select a subset of the most important features from a larger set of features to use as inputs for a model. The goal of feature selection is to reduce the number of features used in the model, while retaining the most important and relevant information from the data.\n",
        "\n",
        "\n",
        "\n",
        "*   Dropping unnecessary columns\n",
        "\n"
      ],
      "metadata": {
        "id": "rO99VbLCmrqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the ID column\n",
        "df_feature.drop('ID',axis = 1, inplace = True)\n",
        "\n",
        "# Dropping Sum_all_pay_amount because it was created for EDA\n",
        "df_feature.drop(['Sum_all_pay_amount'],axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZkPiw9GWmzHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5.5 Handling Imbalance"
      ],
      "metadata": {
        "id": "hZbPo4Onm68Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if our target variable is balanced or not"
      ],
      "metadata": {
        "id": "n7sKsBbDnGRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependant Column Value Counts\n",
        "print(df_feature.DP_NEXT_MONTH.value_counts())\n",
        "print(\" \")\n",
        "\n",
        "# Dependant Variable Column Visualization\n",
        "fig,ax = plt.subplots(1,2, figsize=(15,6))\n",
        "\n",
        "# pie chart for percentage\n",
        "df_feature['DP_NEXT_MONTH'].value_counts().plot(kind='pie',autopct=\"%1.1f%%\",startangle=90, ax=ax[0])\n",
        "\n",
        "# bar chart for count\n",
        "df_feature['DP_NEXT_MONTH'].value_counts().plot(kind='bar', ax=ax[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QWWFObuvnAjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When there are significantly more instances of certain classes than others, the issue of class imbalance typically arises. Class imbalance in the target class is a problem for machine learning models because it can result in biased predictions. That is why we need to balance the target class.\n",
        "\n",
        "The data set differs significantly. Our data, therefore, lack balance. We will use the Synthetic Minority Oversampling Technique (SMOTE) to resolve this issue.\n",
        "\n",
        "*   SMOTE (Synthetic Minority Oversampling Technique) works by randomly selecting a minority class point and calculating its k-nearest neighbors. Between the selected point and its neighbors, the synthetic points are added. Continue with the steps until the data is balanced.\n",
        "\n"
      ],
      "metadata": {
        "id": "bkso2dk5nNrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Handling target class imbalance using SMOTE\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X = df_feature.drop(columns='DP_NEXT_MONTH')     # independent features\n",
        "y = df_feature['DP_NEXT_MONTH']                  # dependent features\n",
        "\n",
        "print(f'Before Handling Imbalanced class {Counter(y)}')\n",
        "\n",
        "# Resampling the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# fit predictor and target variable\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "print(f'After Handling Imbalanced class {Counter(y)}')"
      ],
      "metadata": {
        "id": "tLH7GekJnWOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully balanced the target variable"
      ],
      "metadata": {
        "id": "C8Ec1JaincN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Building"
      ],
      "metadata": {
        "id": "EmR0sXvTSVDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.1 Train Test Split"
      ],
      "metadata": {
        "id": "LpYTP5AySdxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "XrJFnDvSSlCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.2 Scaling Data"
      ],
      "metadata": {
        "id": "rRG5xvY0SiBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling Data\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "wFU69x5ASyL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **6.3 Model Training**"
      ],
      "metadata": {
        "id": "qUcvtHt5S9K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty list for appending performance metric score\n",
        "model_result = []\n",
        "\n",
        "def predict(ml_model, model_name):\n",
        "\n",
        "  '''\n",
        "  Pass the model and predict value.\n",
        "  Function will calculate all the eveluation metrics and appending those metrics score on model_result table.\n",
        "  Plotting confusion_matrix and roc_curve for test data.\n",
        "  '''\n",
        "\n",
        "  # model fitting\n",
        "  model = ml_model.fit(X_train, y_train)\n",
        "\n",
        "  # predicting value and probability\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  y_train_prob = model.predict_proba(X_train)[:,1]\n",
        "  y_test_prob = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "\n",
        "  ''' Performance Metrics '''\n",
        "  # accuracy score  ---->  (TP+TN)/(TP+FP+TN+FN)\n",
        "  train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "  test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "  print(f'train accuracy : {round(train_accuracy,3)}')\n",
        "  print(f'test accuracy : {round(test_accuracy,3)}')\n",
        "\n",
        "  # precision score  ---->  TP/(TP+FP)\n",
        "  train_precision = precision_score(y_train, y_train_pred)\n",
        "  test_precision = precision_score(y_test, y_test_pred)\n",
        "  print(f'train precision : {round(train_precision,3)}')\n",
        "  print(f'test precision : {round(test_precision,3)}')\n",
        "\n",
        "  # recall score  ---->  TP/(TP+FN)\n",
        "  train_recall = recall_score(y_train, y_train_pred)\n",
        "  test_recall = recall_score(y_test, y_test_pred)\n",
        "  print(f'train recall : {round(train_recall,3)}')\n",
        "  print(f'test recall : {round(test_recall,3)}')\n",
        "\n",
        "  # f1 score  ---->  Harmonic Mean of Precision and Recall\n",
        "  train_f1 = f1_score(y_train, y_train_pred)\n",
        "  test_f1 = f1_score(y_test, y_test_pred)\n",
        "  print(f'train f1 : {round(train_f1,3)}')\n",
        "  print(f'test f1 : {round(test_f1,3)}')\n",
        "\n",
        "  # roc_auc score  ---->  It shows how well the model can differentiate between classes.\n",
        "  train_roc_auc = roc_auc_score(y_train, y_train_prob)\n",
        "  test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
        "  print(f'train roc_auc : {round(train_roc_auc,3)}')\n",
        "  print(f'test roc_auc : {round(test_roc_auc,3)}')\n",
        "  print('-'*80)\n",
        "\n",
        "  # classification report\n",
        "  print(f'classification report for test data \\n{classification_report(y_test, y_test_pred)}')\n",
        "  print('-'*80)\n",
        "\n",
        "\n",
        "  ''' plotting Confusion Matrix '''\n",
        "  ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
        "  plt.title('confusion matrix on Test data', weight='bold')\n",
        "  plt.show()\n",
        "  print('-'*80)\n",
        "\n",
        "\n",
        "  ''' actual value vs predicted value on test data'''\n",
        "  d = {'y_actual':y_test, 'y_predict':y_test_pred}\n",
        "  print(pd.DataFrame(data=d).head(10).T)                   # constructing a dataframe with both actual and predicted values\n",
        "  print('-'*80)\n",
        "\n",
        "  '''Calculate threshold values for K-S chart'''\n",
        "\n",
        "  # Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
        "\n",
        "  # Calculate the maximum difference between the true positive rate and false positive rate\n",
        "  ks_stat = tpr - fpr\n",
        "\n",
        "  # Compute the threshold that maximizes the difference between the false positive rate and the true positive rate\n",
        "  ks_threshold = thresholds[np.argmax(ks_stat)]\n",
        "\n",
        "  # Plot the KS chart\n",
        "  plt.plot(thresholds, tpr, label='True Positive Rate')\n",
        "  plt.plot(thresholds, fpr, label='False Positive Rate')\n",
        "  plt.plot(thresholds, ks_stat, label='KS Statistic')\n",
        "  plt.axvline(ks_threshold, color='black', linestyle='--', label=f'KS Threshold: {ks_threshold:.2f}')\n",
        "  plt.title('KS Chart')\n",
        "  plt.xlabel('Threshold')\n",
        "  plt.ylabel('Rate')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  '''Using the score from the performance metrics to create the final model_result'''\n",
        "  model_result.append({'model':model_name,\n",
        "                       'train_accuracy':train_accuracy,\n",
        "                       'test_accuracy':test_accuracy,\n",
        "                       'train_precision':train_precision,\n",
        "                       'test_precision':test_precision,\n",
        "                       'train_recall':train_recall,\n",
        "                       'test_recall':test_recall,\n",
        "                       'train_f1':train_f1,\n",
        "                       'test_f1':test_f1,\n",
        "                       'train_roc_auc':train_roc_auc,\n",
        "                       'test_roc_auc':test_roc_auc})\n",
        ""
      ],
      "metadata": {
        "id": "WC4Sy7oCTRpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 7. Model Implementation"
      ],
      "metadata": {
        "id": "NjZ8WoQxNDR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **7.1 Logistic Regression**"
      ],
      "metadata": {
        "id": "OqTs1VbsNGaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(LogisticRegression(), 'LogisticRegression')"
      ],
      "metadata": {
        "id": "_gtREE4zN_hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.2 KNN (K-Nearest Neighbours)"
      ],
      "metadata": {
        "id": "tSs42WkxOItu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the optimum value of the k:\n",
        "accuracy=[]\n",
        "\n",
        "# Iteratig for the optimum values of k\n",
        "for i in range(1,15):\n",
        "  knn=KNeighborsClassifier(n_neighbors=i)\n",
        "  knn.fit(X_train,y_train)\n",
        "  accuracy.append(knn.score(X_test, y_test))\n",
        "\n",
        "#plotting the k-value vs accuracy\n",
        "plt.title('k-NN Varying number of neighbors')\n",
        "plt.plot(range(1,15), accuracy)\n",
        "plt.xlabel('number of neighbours')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ak327pBCOT9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best accuracy is at K=1. So we will concentrate on low values of k."
      ],
      "metadata": {
        "id": "pMoNRQvfObKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(KNeighborsClassifier(n_neighbors=1), 'KNN')"
      ],
      "metadata": {
        "id": "vO2DyBdLOdEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.3 Decision Tree**"
      ],
      "metadata": {
        "id": "PS4c4WPROqDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(DecisionTreeClassifier(), 'DecisionTree')"
      ],
      "metadata": {
        "id": "Qb4StK3QOxvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.4 Random Forest"
      ],
      "metadata": {
        "id": "upiJM_8eRvzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tunning using RandomizedSearchCV"
      ],
      "metadata": {
        "id": "ifFdLoTsR-Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {'n_estimators': [50,75],           # number of trees in the ensemble\n",
        "             'max_depth': [70,80],              # maximum number of levels allowed in each tree.\n",
        "             'min_samples_split': [2,5],        # minimum number of samples necessary in a node to cause node splitting.\n",
        "             'min_samples_leaf': [3,4]}         # minimum number of samples which can be stored in a tree leaf.\n",
        "\n",
        "\n",
        "\n",
        "# performing Hyperparameter Tunning using RandomizedSearchCV\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_gridsearch = GridSearchCV(estimator=rf, param_grid=rf_params, cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# model fitting\n",
        "rf_gridsearch.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Ap2n09KrSCtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_model = rf_gridsearch.best_estimator_\n",
        "optimal_model"
      ],
      "metadata": {
        "id": "wOAS5XdxSO_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_model =RandomForestClassifier(max_depth=70, min_samples_leaf=3, n_estimators=75,\n",
        "                       random_state=42)\n",
        "predict(optimal_model, 'RandomForest')"
      ],
      "metadata": {
        "id": "eRNVJtgUSR8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}